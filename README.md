## Задача извлечения фрагмента из текста по запросу

Полный отчет по решению задачи описан [здесь](/solution.ipynb).

### Описание задачи

Необходимо создать модель, которая по входной паре `текст документа` и `наименование пункта анкеты` будет возвращать соответствующий этому пункту `фрагмент текста из данного документа`. 

Модель должна помочь отделу госзакупок извлекать нужный кусок текста из документа для того, чтобы сформировать анкету заявки. То, какой именно фрагмент текста нужно извлечь, зависит от пункта анкеты, соответствующего документу.
Всего в каждом документе есть 1 из 2-х пунктов анкеты, по которым необходимо извлекать кусочки из текста:
- обеспечение исполнения контракта,
- обеспечение гарантийных обязательств.

Для оценки решения используется метрика `Accuracy`: доля наблюдений, в которых извлеченный моделью фрагмент текста полностью соответствует фактически требуемому фрагменту.

### Реализация

На первом этапе проведен sanity check и разведочный анализ данных: распределение лейблов, размер датасета, распределение длин текстов, похожесть текстов. 
На втором этапе проведены эксперименты по обучению моделей с применением двух подходов:

- Extractive Question-Answering
- Token Classification

В обоих подходах для fine-tuning использовалась предобученная модель [`cointegrated/rubert-tiny2`](https://huggingface.co/cointegrated/rubert-tiny2).

Веса обученных моделей можно скачать [здесь](https://disk.yandex.ru/d/n5IUJ68aq_oZ7Q).

### Результаты

Модель, обученная решать задачу Extractive QA, показала наилучшие результаты: accuracy равен 0.75. Модель для задачи Token Classification достигла значения метрики 0.6.

### Другие идеи

Так как многие документы имеют одинаковую структуру, к задаче можно также применить rule-based подход. Например, всего 4 регулярных выражения покрывают 26% от текстов с лейблом `обеспечение исполнения контракта`, что говорит о том, что у правилового подхода есть определенный потенциал.

Еще один способ решения данной задачи - Sentence Similarity подход (определение меры схожести двух предложений). Модели, обученные на такую задачу, покрывают семантическую информацию предложений и рассчитывают, насколько она близка для пары предложений. В нашем случае можно было бы определять, насколько каждое предложение в тексте близко запросу (или лейблу). Однако, в силу того, что мы сильно зависим от конкретного фрагмента, а тексты не поделены заранее на предложения (и сделать это самим сложно в силу специфики документов, не имеющих часто даже знаков препинания), то таким способом в данный момент решить задачу затруднительно. Но если поработать над тем, чтобы преобразовать датасет в набор из предложений (и поиск фрагмента проводить по ним), то эксперименты с Sentence Similarity будут иметь смысл.